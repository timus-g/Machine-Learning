{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Solve these exercises in the codeblock below each question and compare your answer"
      ],
      "metadata": {
        "id": "mXDuzbS9WUvr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.How to import pandas and check the version?"
      ],
      "metadata": {
        "id": "1ZI70-Dq4xoc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdqAHGTx4mci"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.Create a pandas series from each of the items below: a list, numpy and a dictionary Input\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "mylist = list('abcedfghijklmnopqrstuvwxyz')\n",
        "\n",
        "myarr = np.arange(26)\n",
        "\n",
        "mydict = dict(zip(mylist, myarr))"
      ],
      "metadata": {
        "id": "xUWxguw55D-C"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ps-EBNwv5Ori"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "a  &nbsp;  0\n",
        "\n",
        "b  &nbsp;  1\n",
        "\n",
        "c  &nbsp;  2\n",
        "\n",
        "d  &nbsp;  4\n",
        "\n",
        "e  &nbsp;  3\n",
        "\n",
        "dtype: int64"
      ],
      "metadata": {
        "id": "-jTGHHjV5Ovp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.Convert the series ser into a dataframe with its index as another column on the dataframe. Input\n",
        "\n",
        "mylist = list('abcedfghijklmnopqrstuvwxyz')\n",
        "\n",
        "myarr = np.arange(26)\n",
        "\n",
        "mydict = dict(zip(mylist, myarr))\n",
        "\n",
        "ser = pd.Series(mydict)"
      ],
      "metadata": {
        "id": "gCC5WukU5plE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aVFu3Uw15shG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  index &nbsp; 0\n",
        "\n",
        "0     a  0\n",
        "\n",
        "1     b  1\n",
        "\n",
        "2     c  2\n",
        "\n",
        "3     d  4\n",
        "\n",
        "4     e  3"
      ],
      "metadata": {
        "id": "wljGoMia5srN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.Combine ser1 and ser2 to form a dataframe.\n",
        "\n",
        "Input\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "ser1 = pd.Series(list('abcedfghijklmnopqrstuvwxyz'))\n",
        "\n",
        "ser2 = pd.Series(np.arange(26)"
      ],
      "metadata": {
        "id": "rgUqlg1w5-o0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "latHZUPE6D9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "&nbsp;  &nbsp;col1  col2\n",
        "\n",
        "0  &nbsp;  a &nbsp;&nbsp;    0\n",
        "\n",
        "1  &nbsp;  b &nbsp;&nbsp;    1\n",
        "\n",
        "2  &nbsp;  c &nbsp;&nbsp;    2\n",
        "\n",
        "3  &nbsp;  e &nbsp;&nbsp;    3\n",
        "\n",
        "4  &nbsp;  d &nbsp;&nbsp;    4"
      ],
      "metadata": {
        "id": "bHR_NL3R6EBQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.Give a name to the series ser calling it ‘alphabets’.\n",
        "\n",
        "Input\n",
        "\n",
        "ser = pd.Series(list('abcedfghijklmnopqrstuvwxyz'))"
      ],
      "metadata": {
        "id": "uANlrx7_6e8s"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jhOYYfe36je8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0    a\n",
        "\n",
        "1    b\n",
        "\n",
        "2    c\n",
        "\n",
        "3    e\n",
        "\n",
        "4    d\n",
        "\n",
        "Name: alphabets, dtype: object"
      ],
      "metadata": {
        "id": "HHND-_o-6jjG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.From ser1 remove items present in ser2.\n",
        "\n",
        "ser1 = pd.Series([1, 2, 3, 4, 5])\n",
        "\n",
        "ser2 = pd.Series([4, 5, 6, 7, 8])"
      ],
      "metadata": {
        "id": "yq1EyCio6qoK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VT0Z-Y_N6up0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0    1\n",
        "\n",
        "1    2\n",
        "\n",
        "2    3\n",
        "\n",
        "dtype: int64"
      ],
      "metadata": {
        "id": "M1Wur-mJ6utc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.Get all items of ser1 and ser2 not common to both. Input\n",
        "\n",
        "ser1 = pd.Series([1, 2, 3, 4, 5])\n",
        "\n",
        "ser2 = pd.Series([4, 5, 6, 7, 8])"
      ],
      "metadata": {
        "id": "HWU0RQTL695c"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E33b2_qs6_os"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0 &nbsp;   1<br>\n",
        "1  &nbsp;  2<br>\n",
        "2  &nbsp;  3<br>\n",
        "5  &nbsp;  6<br>\n",
        "6  &nbsp;  7<br>\n",
        "7  &nbsp;  8<br>\n",
        "dtype: int64\n"
      ],
      "metadata": {
        "id": "BD7RYVNJ6_5E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.Compute the minimum, 25th percentile, median, 75th, and maximum of ser.\n",
        "\n",
        "Input\n",
        "\n",
        "ser = pd.Series(np.random.normal(10, 5, 25))"
      ],
      "metadata": {
        "id": "lKzyUKUfEL5D"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "38POlTt8KV0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "array([  1.39267584,   6.49135133,  10.2578186 ,  13.06985067,  25.80920994])"
      ],
      "metadata": {
        "id": "KPcKOHCbKV5O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.Calculte the frequency counts of each unique value ser.\n",
        "\n",
        " Input\n",
        "\n",
        "ser = pd.Series(np.take(list('abcdefgh'), np.random.randint(8, size=30)))"
      ],
      "metadata": {
        "id": "7O_d8wscKaPK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "trD5B1utKhlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "f  &nbsp;  8<br>\n",
        "g &nbsp;   7<br>\n",
        "b &nbsp;   6<br>\n",
        "c  &nbsp;  4<br>\n",
        "a  &nbsp;  2<br>\n",
        "e  &nbsp;  2<br>\n",
        "h  &nbsp;  1<br>\n",
        "dtype: int64"
      ],
      "metadata": {
        "id": "eznn9DqMKhpf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.From ser, keep the top 2 most frequent items as it is and replace everything else as ‘Other’.\n",
        "\n",
        " Input\n",
        "\n",
        "np.random.RandomState(100)\n",
        "\n",
        "\n",
        "ser = pd.Series(np.random.randint(1, 5, [12]))"
      ],
      "metadata": {
        "id": "My6qmaLxKs3t"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IrU52s94K101"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Top&nbsp; 2 Freq:&nbsp; 4&nbsp;    5<br>\n",
        "3  &nbsp;  3<br>\n",
        "2  &nbsp;  2<br>\n",
        "1  &nbsp;  2<br>\n",
        "dtype: int64<br><br>\n",
        "\n",
        "0  &nbsp;   Other<br>\n",
        "1  &nbsp;   Other<br>\n",
        "2  &nbsp;       3<br>\n",
        "3  &nbsp;       4<br>\n",
        "4  &nbsp;   Other<br>\n",
        "5  &nbsp;       4<br>\n",
        "6  &nbsp;       4<br>\n",
        "7  &nbsp;       3<br>\n",
        "8  &nbsp;       3<br>\n",
        "9  &nbsp;       4<br>\n",
        "10 &nbsp;       4<br>\n",
        "11 &nbsp;   Other<br>\n",
        "dtype:&nbsp; object<br>"
      ],
      "metadata": {
        "id": "u_62isCuK141"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.Bin the series ser into 10 equal deciles and replace the values with the bin name.\n",
        "\n",
        "Input\n",
        "\n",
        "ser = pd.Series(np.random.random(20))"
      ],
      "metadata": {
        "id": "MfLxyl3pLyuq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FOSbNcCeLx3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0 &nbsp;   0.556912\n",
        "\n",
        "1 &nbsp;    0.892955\n",
        "\n",
        "2 &nbsp;    0.566632\n",
        "\n",
        "3 &nbsp;    0.146656\n",
        "\n",
        "4 &nbsp;    0.881579\n",
        "\n",
        "dtype: float64\n",
        "\n",
        "\n",
        "0 &nbsp;   7th\n",
        "\n",
        "1 &nbsp;   9th\n",
        "\n",
        "2 &nbsp;   7th\n",
        "\n",
        "3 &nbsp;   3rd\n",
        "\n",
        "4 &nbsp;   8th\n",
        "\n",
        "dtype: category\n",
        "\n",
        "Categories (10, object): [1st < 2nd < 3rd < 4th ... 7th < 8th < 9th < 10th]"
      ],
      "metadata": {
        "id": "nP9kMkd_NRH7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. Reshape the series ser into a dataframe with 7 rows and 5 columns\n",
        "\n",
        "Input\n",
        "\n",
        "ser = pd.Series(np.random.randint(1, 10, 35))"
      ],
      "metadata": {
        "id": "DqJ7EEcxNpN_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mUNtC4XjNoYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "   0  1  2  3  4\n",
        "\n",
        "0  1  2  1  2  5\n",
        "\n",
        "1  1  2  4  5  2\n",
        "\n",
        "2  1  3  3  2  8\n",
        "\n",
        "3  8  6  4  9  6\n",
        "\n",
        "4  2  1  1  8  5\n",
        "\n",
        "5  3  2  8  5  6\n",
        "\n",
        "6  1  5  5  4  6"
      ],
      "metadata": {
        "id": "qdN4GVdFNxNG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13.Find the positions of numbers that are multiples of 3 from ser.\n",
        "\n",
        " Input\n",
        "\n",
        "ser = pd.Series(np.random.randint(1, 10, 7))"
      ],
      "metadata": {
        "id": "l1atuXy0N8Ef"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g3OegUMvN9_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0    6\n",
        "\n",
        "1    8\n",
        "\n",
        "2    6\n",
        "\n",
        "3    7\n",
        "\n",
        "4    6\n",
        "\n",
        "5    2\n",
        "\n",
        "6    4\n",
        "\n",
        "dtype: int64\n",
        "\n",
        "array([[0],<br>\n",
        "  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[2],<br>\n",
        "       &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[4]])"
      ],
      "metadata": {
        "id": "V3_gxeOAN-Da"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14.From ser, extract the items at positions in list pos.\n",
        "\n",
        " Input\n",
        "\n",
        "ser = pd.Series(list('abcdefghijklmnopqrstuvwxyz'))\n",
        "\n",
        "pos = [0, 4, 8, 14, 20]"
      ],
      "metadata": {
        "id": "7aG8GJvzOfmH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LyyCeurYOmqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0     a<br>\n",
        "4     e<br>\n",
        "8     i<br>\n",
        "14    o<br>\n",
        "20    u<br>\n",
        "dtype: object"
      ],
      "metadata": {
        "id": "kQREQfpvOmuq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15.Stack ser1 and ser2 vertically and horizontally (to form a dataframe).\n",
        "\n",
        "Input\n",
        "\n",
        "ser1 = pd.Series(range(5))\n",
        "\n",
        "ser2 = pd.Series(list('abcde'))"
      ],
      "metadata": {
        "id": "qe_pT0_vOt1g"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l7e7hFaNOzL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " &nbsp;&nbsp;  0  1<br>\n",
        "0  0  a<br>\n",
        "1  1  b<br>\n",
        "2  2  c<br>\n",
        "3  3  d<br>\n",
        "4  4  e<br>"
      ],
      "metadata": {
        "id": "52jFKUOvOzQ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16.Get the positions of items of ser2 in ser1 as a list.\n",
        "\n",
        "Input\n",
        "\n",
        "ser1 = pd.Series([10, 9, 6, 5, 3, 1, 12, 8, 13])\n",
        "\n",
        "ser2 = pd.Series([1, 3, 10, 13])"
      ],
      "metadata": {
        "id": "U4tFZ6sRPASv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D84l2dHAPGEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[5, 4, 0, 8]"
      ],
      "metadata": {
        "id": "j6OBLcGEPGI0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17.Compute the mean squared error of truth and pred series.\n",
        "\n",
        " Input\n",
        "\n",
        "truth = pd.Series(range(10))\n",
        "\n",
        "pred = pd.Series(range(10)) + np.random.random(10)"
      ],
      "metadata": {
        "id": "MTWXvY94PJMf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RK4p4i-NPPn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0.28448128110629545"
      ],
      "metadata": {
        "id": "la9-fXSuPPte"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18.Change the first character of each word to upper case in each word of ser.\n",
        "\n",
        "ser = pd.Series(['how', 'to', 'kick', 'ass?'])"
      ],
      "metadata": {
        "id": "Tz8osXEAPQU3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DXRtNcdkPW1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0     How<br>\n",
        "1      To<br>\n",
        "2    Kick<br>\n",
        "3    Ass?<br>\n",
        "dtype: object"
      ],
      "metadata": {
        "id": "wf-DdmFMPW6O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19.Calculate the number of characters in each word in a series?\n",
        "\n",
        "Input\n",
        "\n",
        "ser = pd.Series(['how', 'to', 'kick', 'ass?'])"
      ],
      "metadata": {
        "id": "fT5rhFCVPcuN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ljbiwvVmPncX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0    3<br>\n",
        "1    2<br>\n",
        "2    4<br>\n",
        "3    4<br>\n",
        "dtype: int64"
      ],
      "metadata": {
        "id": "5axL8HfSPnir"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20.Difference of differences between the consequtive numbers of ser.\n",
        "\n",
        " Input\n",
        "\n",
        "ser = pd.Series([1, 3, 6, 10, 15, 21, 27, 35])"
      ],
      "metadata": {
        "id": "PBd7FdoBPwrD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2FWVJYtkP2CG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[nan, 2.0, 3.0, 4.0, 5.0, 6.0, 6.0, 8.0]\n",
        "\n",
        "[nan, nan, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0]"
      ],
      "metadata": {
        "id": "e_4G5-iHP2Fx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21.convert a series of date-strings to a timeseries\n",
        "\n",
        " Input\n",
        "\n",
        "ser = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])"
      ],
      "metadata": {
        "id": "tnDK1OGzP84O"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9k-UcVtBQE34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0   2010-01-01 00:00:00\n",
        "\n",
        "1   2011-02-02 00:00:00\n",
        "\n",
        "2   2012-03-03 00:00:00\n",
        "\n",
        "3   2013-04-04 00:00:00\n",
        "\n",
        "4   2014-05-05 00:00:00\n",
        "\n",
        "5   2015-06-06 12:20:00\n",
        "\n",
        "dtype: datetime64[ns]"
      ],
      "metadata": {
        "id": "vlWdX8BpQE8d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "22.Get the day of month, week number, day of year and day of week from ser.\n",
        "\n",
        "Input\n",
        "\n",
        "ser = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])"
      ],
      "metadata": {
        "id": "_2hwbZvkQJ7m"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cc0DxHRxY53I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Date:  [1, 2, 3, 4, 5, 6]\n",
        "\n",
        "Week number:  [53, 5, 9, 14, 19, 23]\n",
        "\n",
        "Day num of year:  [1, 33, 63, 94, 125, 157]\n",
        "\n",
        "Day of week:  ['Friday', 'Wednesday', 'Saturday', 'Thursday', 'Monday', 'Saturday']"
      ],
      "metadata": {
        "id": "lp7512tUY57s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "23.Change ser to dates that start with 4th of the respective months.\n",
        "\n",
        "Input\n",
        "\n",
        "ser = pd.Series(['Jan 2010', 'Feb 2011', 'Mar 2012'])"
      ],
      "metadata": {
        "id": "fPwYCl5JY-r1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mLXdrsKaY-ng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0   2010-01-04\n",
        "\n",
        "1   2011-02-04\n",
        "\n",
        "2   2012-03-04\n",
        "\n",
        "dtype: datetime64[ns]"
      ],
      "metadata": {
        "id": "k8u5t4sQZH3I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "24.From ser, extract words that contain atleast 2 vowels.\n",
        "\n",
        " Input\n",
        "\n",
        "ser = pd.Series(['Apple', 'Orange', 'Plan', 'Python', 'Money'])"
      ],
      "metadata": {
        "id": "d4X0paeyZPX7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8HTC6vl2ZXYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0     Apple\n",
        "\n",
        "1    Orange\n",
        "\n",
        "4     Money\n",
        "\n",
        "dtype: object"
      ],
      "metadata": {
        "id": "aB23U9cjZXbv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "25. Extract the valid emails from the series emails. The regex pattern for valid emails is provided as reference.\n",
        "\n",
        "Input\n",
        "\n",
        "emails = pd.Series(['buying books at amazom.com', 'rameses@egypt.com', 'matt@t.co', 'narendra@modi.com'])\n",
        "\n",
        "pattern ='[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\\\.[A-Za-z]{2,4}'"
      ],
      "metadata": {
        "id": "yILSufZsZfCq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "93l2yJPNZo0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1    rameses@egypt.com\n",
        "\n",
        "2            matt@t.co\n",
        "\n",
        "3    narendra@modi.com\n",
        "\n",
        "dtype: object"
      ],
      "metadata": {
        "id": "oH_u3_qXZo4O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "26.Compute the mean of weights of each fruit.\n",
        "<br> Input\n",
        "\n",
        "fruit = pd.Series(np.random.choice(['apple', 'banana', 'carrot'], 10))<br>\n",
        "weights = pd.Series(np.linspace(1, 10, 10))<br>\n",
        "print(weight.tolist())<br>\n",
        "print(fruit.tolist())<br>\n",
        "> [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]<br>\n",
        "> ['banana', 'carrot', 'apple', 'carrot', 'carrot', 'apple', 'banana', 'carrot', 'apple', 'carrot']\n",
        "\n"
      ],
      "metadata": {
        "id": "eBIT9_m8ZtIb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2U1PNv7JZ-SN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "values can change due to randomness\n",
        "\n",
        "apple     6.0\n",
        "\n",
        "banana    4.0\n",
        "\n",
        "carrot    5.8\n",
        "\n",
        "dtype: float64"
      ],
      "metadata": {
        "id": "vyZb_t4PZ-WE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "27.Compute the euclidean distance between series (points) p and q, without using a packaged formula.<br> Input<br>\n",
        "\n",
        "p = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])<br>\n",
        "q = pd.Series([10, 9, 8, 7, 6, 5, 4, 3, 2, 1])"
      ],
      "metadata": {
        "id": "RYJxHIpIaKw0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cHiri_i7aTTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "18.165"
      ],
      "metadata": {
        "id": "pbL2MBz0aTWL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "28.Get the positions of peaks (values surrounded by smaller values on both sides) in ser.\n",
        "\n",
        " Input\n",
        "\n",
        "ser = pd.Series([2, 10, 3, 4, 9, 10, 2, 7, 3])"
      ],
      "metadata": {
        "id": "7YmGrMNpaWlA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DyVFmsQfaeWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "array([1, 5, 7])"
      ],
      "metadata": {
        "id": "XpI3V5vbaeZw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "29.Replace the spaces in my_str with the least frequent character.\n",
        "\n",
        "Input\n",
        "\n",
        "my_str = 'dbc deb abed gade'"
      ],
      "metadata": {
        "id": "T7yU5QFsagnf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y9U5WjhUaqeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "'dbccdebcabedcgade'  # least frequent is 'c'"
      ],
      "metadata": {
        "id": "MvYOkXj_aqhc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "30.create a TimeSeries starting ‘2000-01-01’ and 10 weekends (saturdays) after that having random numbers as values?"
      ],
      "metadata": {
        "id": "8dR-ftUcatGB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JLB8h8lZtfaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " values can be random\n",
        "\n",
        "2000-01-01   &nbsp;4\n",
        "\n",
        "2000-01-08    &nbsp;1\n",
        "\n",
        "2000-01-15    &nbsp;8\n",
        "\n",
        "2000-01-22    &nbsp;4\n",
        "\n",
        "2000-01-29    &nbsp;4\n",
        "\n",
        "2000-02-05    &nbsp;2\n",
        "\n",
        "2000-02-12    &nbsp;4\n",
        "\n",
        "2000-02-19    &nbsp;9\n",
        "\n",
        "2000-02-26    &nbsp;6\n",
        "\n",
        "2000-03-04    &nbsp;6"
      ],
      "metadata": {
        "id": "yJEfoZR2tfeX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "31.ser has missing dates and values. Make all missing dates appear and fill up with value from previous date. <br>Input<br>\n",
        "\n",
        "ser = pd.Series([1,10,3,np.nan], index=pd.to_datetime(['2000-01-01', '2000-01-03', '2000-01-06', '2000-01-08']))<br>\n",
        "print(ser)<br>\n",
        "> 2000-01-01     1.0<br>\n",
        "> 2000-01-03    10.0<br>\n",
        "> 2000-01-06     3.0<br>\n",
        "> 2000-01-08     NaN<br>\n",
        "> dtype: float64"
      ],
      "metadata": {
        "id": "hf2U5hAQtsAT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o2OZMzPFt_qN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2000-01-01     1.0<br>\n",
        "2000-01-02     1.0<br>\n",
        "2000-01-03    10.0<br>\n",
        "2000-01-04    10.0<br>\n",
        "2000-01-05    10.0<br>\n",
        "2000-01-06     3.0<br>\n",
        "2000-01-07     3.0<br>\n",
        "2000-01-08     NaN"
      ],
      "metadata": {
        "id": "8QrnsP52t_t0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "32.Compute autocorrelations for the first 10 lags of ser. Find out which lag has the largest correlation.<br> Input<br>\n",
        "\n",
        "ser = pd.Series(np.arange(20) + np.random.normal(1, 10, 20))"
      ],
      "metadata": {
        "id": "wBy-mdtVuHNw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jedMPkOauQfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " values will change due to randomness<br>\n",
        "[0.29999999999999999, -0.11, -0.17000000000000001, 0.46000000000000002, 0.28000000000000003, -0.040000000000000001, -0.37, 0.41999999999999998, 0.47999999999999998, 0.17999999999999999]<br>\n",
        "Lag having highest correlation:  9"
      ],
      "metadata": {
        "id": "QUE9xdnDuQjB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "33.Import every 50th row of BostonHousing dataset as a dataframe. <br>\n",
        "URL:https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv"
      ],
      "metadata": {
        "id": "kIRWD1-9uZBk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0utU6CwOuljr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "                  crim    zn  indus chas                  nox     rm   age  \n",
        "0              0.21977   0.0   6.91    0  0.44799999999999995  5.602  62.0   \n",
        "1               0.0686   0.0   2.89    0                0.445  7.416  62.5   \n",
        "2   2.7339700000000002   0.0  19.58    0                0.871  5.597  94.9   \n",
        "3               0.0315  95.0   1.47    0  0.40299999999999997  6.975  15.3   \n",
        "4  0.19072999999999998  22.0   5.86    0                0.431  6.718  17.5   \n",
        "\n",
        "     dis rad  tax ptratio       b  lstat  medv  \n",
        "0  6.0877   3  233    17.9   396.9   16.2  19.4  \n",
        "1  3.4952   2  276    18.0   396.9   6.19  33.2  \n",
        "2  1.5257   5  403    14.7  351.85  21.45  15.4  \n",
        "3  7.6534   3  402    17.0   396.9   4.56  34.9  \n",
        "4  7.8265   7  330    19.1  393.74   6.56  26.2  "
      ],
      "metadata": {
        "id": "JfI8t9_5ulms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "34.Import the boston housing dataset, but while importing change the 'medv' (median house value) column so that values < 25 becomes ‘Low’ and > 25 becomes ‘High’.\n",
        "\n",
        "URL:https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv"
      ],
      "metadata": {
        "id": "pRa3cZT2u25E"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I9lyuL9Tu-YT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "array([[ 0,  1,  2,  3],<br>\n",
        "       [ 2,  3,  4,  5],<br>\n",
        "       [ 4,  5,  6,  7],<br>\n",
        "       [ 6,  7,  8,  9],<br>\n",
        "       [ 8,  9, 10, 11],<br>\n",
        "       [10, 11, 12, 13]])"
      ],
      "metadata": {
        "id": "lbCfB6Whu-cC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "35.create a dataframe with rows as strides from a given series?\n",
        "\n",
        " Input\n",
        "\n",
        "L = pd.Series(range(15))"
      ],
      "metadata": {
        "id": "jarlvQzA2KWh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JssQGGVP2QvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "array([[ 0,  1,  2,  3],<br>\n",
        "       [ 2,  3,  4,  5],<br>\n",
        "       [ 4,  5,  6,  7],<br>\n",
        "       [ 6,  7,  8,  9],<br>\n",
        "       [ 8,  9, 10, 11],<br>\n",
        "       [10, 11, 12, 13]])"
      ],
      "metadata": {
        "id": "eh_j6E3j2Qzm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "36.Import ‘crim’ and ‘medv’ columns of the BostonHousing dataset as a dataframe.\n",
        "\n",
        "URL:https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv"
      ],
      "metadata": {
        "id": "QiIut6qyvDx9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c6x-VaD62bcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "      crim  medv\n",
        "0  0.00632  24.0<br>\n",
        "1  0.02731  21.6<br>\n",
        "2  0.02729  34.7<br>\n",
        "3  0.03237  33.4<br>\n",
        "4  0.06905  36.2"
      ],
      "metadata": {
        "id": "0zqV4jHr2bhB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "37.Get the number of rows, columns, datatype and summary statistics of each column of the Cars93 dataset. Also get the numpy array and list equivalent of the dataframe.\n",
        "\n",
        "URL:https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv"
      ],
      "metadata": {
        "id": "fpN9ubiU2l2k"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fkumu0Wx2u9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(93, 27)<br>\n",
        "Manufacturer           object<br>\n",
        "Model                  object<br>\n",
        "Type                   object<br>\n",
        "Min.Price             float64<br>\n",
        "Price                 float64<br>\n",
        "Max.Price             float64<br>\n",
        "MPG.city              float64<br>\n",
        "MPG.highway           float64<br>\n",
        "AirBags                object<br>\n",
        "DriveTrain             object<br>\n",
        "Cylinders              object<br>\n",
        "EngineSize            float64<br>\n",
        "Horsepower            float64<br>\n",
        "RPM                   float64<br>\n",
        "Rev.per.mile          float64<br>\n",
        "Man.trans.avail        object<br>\n",
        "Fuel.tank.capacity    float64<br>\n",
        "Passengers            float64<br>\n",
        "Length                float64<br>\n",
        "Wheelbase             float64<br>\n",
        "Width                 float64<br>\n",
        "Turn.circle           float64<br>\n",
        "Rear.seat.room        float64<br>\n",
        "Luggage.room          float64<br>\n",
        "Weight                float64<br>\n",
        "Origin                 object<br>\n",
        "Make                   object<br>\n",
        "dtype: object<br>\n",
        "float64    18<br>\n",
        "object      9<br>\n",
        "dtype: int64<br>\n",
        "float64    18<br>\n",
        "object      9<br>\n",
        "dtype: int64"
      ],
      "metadata": {
        "id": "WpELxGaB2vBL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vSZDIeZU3E2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "38.extract the row and column number of a particular cell with given criterion?\n",
        "\n",
        " Input\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
        "\n",
        "Which manufacturer, model and type has the highest Price? What is the row and column number of the cell with the highest Price value?"
      ],
      "metadata": {
        "id": "40uEcEO13E6t"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KWi--1sj3XUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "61.899999999999999"
      ],
      "metadata": {
        "id": "29dTIbut3XZi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "39.Rename the column Type as CarType in df and replace the ‘.’ in column names with ‘_’. Input\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
        "\n",
        "print(df.columns)\n",
        "\n",
        "> Index(['Manufacturer', 'Model', 'Type', 'Min.Price', 'Price', 'Max.Price',\n",
        ">        'MPG.city', 'MPG.highway', 'AirBags', 'DriveTrain', 'Cylinders',\n",
        ">        'EngineSize', 'Horsepower', 'RPM', 'Rev.per.mile', 'Man.trans.avail',\n",
        ">        'Fuel.tank.capacity', 'Passengers', 'Length', 'Wheelbase', 'Width',\n",
        ">        'Turn.circle', 'Rear.seat.room', 'Luggage.room', 'Weight', 'Origin',\n",
        ">        'Make'],\n",
        ">       dtype='object')"
      ],
      "metadata": {
        "id": "uKtqP-ID3wtU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zcw4UDdv39B0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "print(df.columns)\n",
        "> Index(['Manufacturer', 'Model', 'CarType', 'Min_Price', 'Price', 'Max_Price',\n",
        ">        'MPG_city', 'MPG_highway', 'AirBags', 'DriveTrain', 'Cylinders',\n",
        ">        'EngineSize', 'Horsepower', 'RPM', 'Rev_per_mile', 'Man_trans_avail',\n",
        ">        'Fuel_tank_capacity', 'Passengers', 'Length', 'Wheelbase', 'Width',\n",
        ">        'Turn_circle', 'Rear_seat_room', 'Luggage_room', 'Weight', 'Origin',\n",
        ">        'Make'],\n",
        ">       dtype='object')"
      ],
      "metadata": {
        "id": "tYxgo4zw39GY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "40.Check if df has any missing values.\n",
        "\n",
        "Input\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')"
      ],
      "metadata": {
        "id": "NtKNpcYn4BVf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vnQDm_f24HuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "true"
      ],
      "metadata": {
        "id": "IH1lqWLV4R1V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "41. Count the number of missing values in each column of df. Which column has the maximum number of missing values?\n",
        "\n",
        " Input\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
        "\n"
      ],
      "metadata": {
        "id": "92EmkKEB4Pwd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lzJyfX4N4axO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "'Luggage.room'"
      ],
      "metadata": {
        "id": "ly8-4wts4a1J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "42.Replace missing values in Min.Price and Max.Price columns with their respective mean.\n",
        "\n",
        " Input\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')"
      ],
      "metadata": {
        "id": "Ilaa7ovc4byE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F0I6hNxP4iiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "   Min.Price  Max.Price<br>\n",
        "0  12.900000  18.800000<br>\n",
        "1  29.200000  38.700000<br>\n",
        "2  25.900000  32.300000<br>\n",
        "3  17.118605  44.600000<br>\n",
        "4  17.118605  21.459091"
      ],
      "metadata": {
        "id": "2XlBnkfj4imw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "43.In df, use apply method to replace the missing values in Min.Price with the column’s mean and those in Max.Price with the column’s median.\n",
        "\n",
        "Input\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')"
      ],
      "metadata": {
        "id": "zEcIrs2bI9Yf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "65-HR99DJHJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "741TzvLNJHOv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "44.Get the first column (a) in df as a dataframe (rather than as a Series).\n",
        "\n",
        "Input\n",
        "\n",
        "df = pd.DataFrame(np.arange(20).reshape(-1, 5), columns=list('abcde'))"
      ],
      "metadata": {
        "id": "i-O0mP7XKRMd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DMclPHUwKeGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5BP3tQT2KeMZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "45.    In df, interchange columns 'a' and 'c'.\n",
        "\n",
        "    Create a generic function to interchange two columns, without hardcoding column names.\n",
        "    \n",
        "    Sort the columns in reverse alphabetical order, that is colume 'e' first through column 'a' last.\n",
        "\n",
        "Input\n",
        "\n",
        "df = pd.DataFrame(np.arange(20).reshape(-1, 5), columns=list('abcde'))"
      ],
      "metadata": {
        "id": "AOtFHiFYKemO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pUlWMPlYKmiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qRDExjTYKmn0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "46.Change the pamdas display settings on printing the dataframe df it shows a maximum of 10 rows and 10 columns.\n",
        "\n",
        " Input\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')"
      ],
      "metadata": {
        "id": "pgyK4P4hK3C8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E1oYzFErLAW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XlJsZgv9LA0f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "47.Suppress scientific notations like ‘e-03’ in df and print upto 4 numbers after decimal.\n",
        "\n",
        " Input\n",
        "\n",
        "df = pd.DataFrame(np.random.random(4)**10, columns=['random'])\n",
        "\n",
        "df\n",
        "\n",
        ">          random\n",
        "> 0  3.474280e-03<br>\n",
        "> 1  3.951517e-05<br>\n",
        "> 2  7.469702e-02<br>\n",
        "> 3  5.541282e-28"
      ],
      "metadata": {
        "id": "7esu4nrzLBAY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qL3yyP24LPH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">    random<br>\n",
        "> 0  0.0035<br>\n",
        "> 1  0.0000<br>\n",
        "> 2  0.0747<br>\n",
        "> 3  0.0000"
      ],
      "metadata": {
        "id": "UCyaFL0KLPMm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "48.Format the values in column 'random' of df as percentages.\n",
        "\n",
        " Input\n",
        "\n",
        "df = pd.DataFrame(np.random.random(4), columns=['random'])\n",
        "\n",
        "df\n",
        "\n",
        ">      random\n",
        "> 0    .689723<br>\n",
        "> 1    .957224<br>\n",
        "> 2    .159157<br>\n",
        "> 3    .21082"
      ],
      "metadata": {
        "id": "wjTlK9HvLXJU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lJ1UXANgLkv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">      random\n",
        "> 0    68.97%<br>\n",
        "> 1    95.72%<br>\n",
        "> 2    15.91%<br>\n",
        "> 3    2.10%"
      ],
      "metadata": {
        "id": "5Kh27snqLk0y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "49.From df, filter the 'Manufacturer', 'Model' and 'Type' for every 20th row starting from 1st (row 0).\n",
        "\n",
        " Input\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
        "\n"
      ],
      "metadata": {
        "id": "ujSWJQD0LsKk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7NFvvnywL0Lb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">   &nbsp;&nbsp;&nbsp;Manufacturer    Model     Type<br>\n",
        "0         Acura  Integra    Small<br>\n",
        "20     Chrysler  LeBaron  Compact<br>\n",
        "40        Honda  Prelude   Sporty<br>\n",
        "60      Mercury   Cougar  Midsize<br>\n",
        "80       Subaru   Loyale    Small"
      ],
      "metadata": {
        "id": "1d_nxSSFL0Qq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "50.In df, Replace NaNs with ‘missing’ in columns 'Manufacturer', 'Model' and 'Type' and create a index as a combination of these three columns and check if the index is a primary key.\n",
        "\n",
        "Input\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv', usecols=[0,1,2,3,5])"
      ],
      "metadata": {
        "id": "FRvjbKBKMHGN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i_01yUmBMNKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manufacturer    Model     Type  Min.Price  Max.Price<br>\n",
        "Acura_Integra_Small           Acura  Integra    Small       12.9       18.8<br>\n",
        "missing_Legend_Midsize      missing   Legend  Midsize       29.2       38.7<br>\n",
        "Audi_90_Compact                Audi       90  Compact       25.9       32.3<br>\n",
        "Audi_100_Midsize               Audi      100  Midsize        NaN       44.6<br>\n",
        "BMW_535i_Midsize                BMW     535i  Midsize        NaN        NaN"
      ],
      "metadata": {
        "id": "MLbIXXXhMNY7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "51.Find the row position of the 5th largest value of column 'a' in df.\n",
        "\n",
        "Input\n",
        "\n",
        "df = pd.DataFrame(np.random.randint(1, 30, 30).reshape(10,-1), columns=list('abc'))"
      ],
      "metadata": {
        "id": "ryHZZzrwMbrc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U10Lra9YMhXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " &nbsp;&nbsp;&nbsp;a&nbsp;&nbsp;b&nbsp;&nbsp;   c<br>\n",
        "0  27   7  25<br>\n",
        "1   8   4  20<br>\n",
        "2   1   7  17<br>\n",
        "3  24   9  17<br>\n",
        "4  21  15   9<br>\n",
        "5  21  16  20<br>\n",
        "6  19  27  25<br>\n",
        "7  12   8  20<br>\n",
        "8  11  16  28<br>\n",
        "9  24  13   4<br>\n",
        "\n",
        "4"
      ],
      "metadata": {
        "id": "UXmOB_Z4Mhcm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "52.In ser, find the position of the 2nd largest value greater than the mean.\n",
        "\n",
        "Input\n",
        "\n",
        "ser = pd.Series(np.random.randint(1, 100, 15))"
      ],
      "metadata": {
        "id": "sLVGQvFaM2nL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hE9EJMFmM7Lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ser:  [7, 77, 16, 86, 60, 38, 34, 36, 83, 27, 16, 52, 50, 52, 54] mean:  46\n",
        "\n",
        "array([3])\n"
      ],
      "metadata": {
        "id": "saxPulAUM7U7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "53.Get the last two rows of df whose row sum is greater than 100.\n",
        "\n",
        "df = pd.DataFrame(np.random.randint(10, 40, 60).reshape(-1, 4))"
      ],
      "metadata": {
        "id": "lB-YDWC4NBE2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jm467EWlNTq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;   1&nbsp;&nbsp;&nbsp;   2&nbsp;&nbsp;   3<br>\n",
        "10  27  35  18  21<br>\n",
        "11  37  26  15  23\n"
      ],
      "metadata": {
        "id": "yZruop3HNTxJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "54.Replace all values of ser in the lower 5%ile and greater than 95%ile with respective 5th and 95th %ile value.\n",
        "\n",
        "Input\n",
        "\n",
        "ser = pd.Series(np.logspace(-2, 2, 30))"
      ],
      "metadata": {
        "id": "S7_Q4IV3N3Hh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b6PAYcrON8co"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0.05 %ile:  0.016049294077 | 0.95 %ile:  63.8766722202"
      ],
      "metadata": {
        "id": "KFYALzzYN8hR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "55.Reshape df to the largest possible square with negative values removed. Drop the smallest values if need be. The order of the positive numbers in the result should remain the same as the original.\n",
        "\n",
        "Input\n",
        "\n",
        "df = pd.DataFrame(np.random.randint(-20, 50, 100).reshape(10,-1))"
      ],
      "metadata": {
        "id": "0_fs2CR4N9Li"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ayWKE8gKOCL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    0   1   2   3   4   5   6   7   8   9\n",
        "0  25 -13  17  16   0   6  22  44  10 -19<br>\n",
        "1  47   4  -1  29 -13  12  41 -13  49  42<br>\n",
        "2  20 -20   9  16 -17  -1  37  39  41  37<br>\n",
        "3  27  44  -5   5   3 -12   0 -13  23  45<br>\n",
        "4   8  27  -8  -3  48 -16  -5  40  16  10<br>\n",
        "5  12  12  41 -12   3 -17  -3  27 -15  -1<br>\n",
        "6  -9  -3  41 -13   1   0  28  33  -2  18<br>\n",
        "7  18 -14  35   5   4  14   4  44  14  34<br>\n",
        "8   1  24  26  28 -10  17 -14  14  38  17<br>\n",
        "9  13  12   5   9 -16  -7  12 -18   1  24<br>\n",
        "[[ 25.  17.  16.   6.  22.  44.  10.  47.]<br>\n",
        " [  4.  29.  12.  41.  49.  42.  20.   9.]<br>\n",
        " [ 16.  37.  39.  41.  37.  27.  44.   5.]<br>\n",
        " [  3.  23.  45.   8.  27.  48.  40.  16.]<br>\n",
        " [ 10.  12.  12.  41.   3.  27.  41.  28.]<br>\n",
        " [ 33.  18.  18.  35.   5.   4.  14.   4.]<br>\n",
        " [ 44.  14.  34.  24.  26.  28.  17.  14.]<br>\n",
        " [ 38.  17.  13.  12.   5.   9.  12.  24.]]<br>"
      ],
      "metadata": {
        "id": "_peBiacdOCZl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "56.Swap rows 1 and 2 in df.\n",
        "\n",
        " Input\n",
        "\n",
        "df = pd.DataFrame(np.arange(25).reshape(5, -1))"
      ],
      "metadata": {
        "id": "qYI2TlcmOR7w"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lmo73lGTOVkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "&nbsp;&nbsp;&nbsp;    0&nbsp;&nbsp;   1&nbsp;&nbsp;   2&nbsp;&nbsp;   3&nbsp;&nbsp;&nbsp;   4<br>\n",
        "4  20  21  22  23  24<br>\n",
        "3  15  16  17  18  19<br>\n",
        "2  10  11  12  13  14<br>\n",
        "1 &nbsp;&nbsp;  5&nbsp;   6&nbsp;   7&nbsp;&nbsp;&nbsp;   8&nbsp;&nbsp;&nbsp;   9<br>\n",
        "0 &nbsp;&nbsp;  0&nbsp;   1&nbsp;   2&nbsp;&nbsp;&nbsp;   3&nbsp;&nbsp;&nbsp;   4<br>"
      ],
      "metadata": {
        "id": "Fz8G-8CfOVqL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "57.Reverse all the rows of dataframe df.\n",
        "\n",
        " Input\n",
        "\n",
        "df = pd.DataFrame(np.arange(25).reshape(5, -1))"
      ],
      "metadata": {
        "id": "9YE_tyHoO3GI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GoqJ142jPB0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "&nbsp;&nbsp;    0&nbsp;&nbsp;   1&nbsp;&nbsp;   2&nbsp;&nbsp;&nbsp;   3&nbsp;&nbsp;&nbsp;   4<br>\n",
        "4  20  21  22  23  24<br>\n",
        "3  15  16  17  18  19<br>\n",
        "2  10  11  12  13  14<br>\n",
        "1  &nbsp; 5&nbsp;&nbsp;&nbsp;   6&nbsp;&nbsp;   7&nbsp;&nbsp;   8&nbsp;&nbsp;   9<br>\n",
        "0&nbsp;   0&nbsp;&nbsp;&nbsp;   1&nbsp;&nbsp;   2&nbsp;&nbsp;   3&nbsp;&nbsp;&nbsp;   4<br>"
      ],
      "metadata": {
        "id": "yTLYNbcqPB6J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "58. Get one-hot encodings for column 'a' in the dataframe df and append it as columns.\n",
        "\n",
        "Input\n",
        "\n",
        "df = pd.DataFrame(np.arange(25).reshape(5,-1), columns=list('abcde'))\n",
        "\n",
        "&nbsp;&nbsp;    a&nbsp;&nbsp;&nbsp;   b&nbsp;&nbsp;   c&nbsp;&nbsp;   d&nbsp;&nbsp;   e\n",
        "\n",
        "0   0&nbsp;&nbsp;&nbsp;   1&nbsp;&nbsp;   2&nbsp;&nbsp;   3&nbsp;&nbsp;   4\n",
        "\n",
        "1   5&nbsp;&nbsp;&nbsp;   6&nbsp;&nbsp;   7&nbsp;&nbsp;   8&nbsp;&nbsp;   9\n",
        "\n",
        "2  10  11  12  13  14\n",
        "\n",
        "3  15  16  17  18  19\n",
        "\n",
        "4  20  21  22  23  24"
      ],
      "metadata": {
        "id": "XJXeRyIIPfnP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D0vKFBOhP_j_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "&nbsp;&nbsp;   0  5  10  15  20   b   c   d   e<br>\n",
        "0  1  0&nbsp;&nbsp;   0&nbsp;&nbsp;   0&nbsp;&nbsp;   0&nbsp;   1   2   3   4<br>\n",
        "1  0  1&nbsp;&nbsp;   0&nbsp;&nbsp;   0&nbsp;&nbsp;   0&nbsp;   6   7   8   9<br>\n",
        "2  0  0   1   0   0  11  12  13  14<br>\n",
        "3  0  0   0   1   0  16  17  18  19<br>\n",
        "4  0  0   0   0   1  21  22  23  24<br>"
      ],
      "metadata": {
        "id": "ejf6rY0-P_pU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KXwP3GdfQeQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "59.Obtain the column name with the highest number of row-wise maximum’s in df.\n",
        "\n",
        "df = pd.DataFrame(np.random.randint(1,100, 40).reshape(10, -1))"
      ],
      "metadata": {
        "id": "PO_Vr7rdQeVl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d253J2XmQkdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Column with highest row maxes:  2"
      ],
      "metadata": {
        "id": "Xgtnqrp3QkhV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "60.Create a new column such that, each row contains the row number of nearest row-record by euclidean distance.\n",
        "\n",
        "df = pd.DataFrame(np.random.randint(1,100, 40).reshape(10, -1), columns=list('pqrs'), index=list('abcdefghij'))\n",
        "\n",
        "df\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;     p&nbsp;&nbsp;   q &nbsp;&nbsp;  r&nbsp;&nbsp;   s<br>\n",
        " a  57  77  13  62<br>\n",
        " b  68   5  92  24<br>\n",
        " c  74  40  18  37<br>\n",
        " d  80  17  39  60<br>\n",
        " e  93  48  85  33<br>\n",
        " f  69  55   8  11<br>\n",
        " g  39  23  88  53<br>\n",
        " h  63  28  25  61<br>\n",
        " i  18   4  73   7<br>\n",
        " j  79  12  45  34<br>"
      ],
      "metadata": {
        "id": "kiBjvZk2QnCu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HxIYKw4BQ-HL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "df\n",
        "\n",
        "    p   q   r   s nearest_row   dist\n",
        " a  57  77  13  62           i  116.0<br>\n",
        " b  68   5  92  24           a  114.0<br>\n",
        " c  74  40  18  37           i   91.0<br>\n",
        " d  80  17  39  60           i   89.0<br>\n",
        " e  93  48  85  33           i   92.0<br>\n",
        " f  69  55   8  11           g  100.0<br>\n",
        " g  39  23  88  53           f  100.0<br>\n",
        " h  63  28  25  61           i   88.0<br>\n",
        " i  18   4  73   7           a  116.0<br>\n",
        " j  79  12  45  34           a   81.0"
      ],
      "metadata": {
        "id": "EIuSZzjcQ-0L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "61.Compute maximum possible absolute correlation value of each column against other columns in df.\n",
        "Input\n",
        "\n",
        "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1), columns=list('pqrstuvwxy'), index=list('abcdefgh'))"
      ],
      "metadata": {
        "id": "4ou3QUu3RVZX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H6qS4lpQRdiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Maximum Correlation possible for each column:  [ 0.91  0.57  0.55  0.71  0.53  0.26  0.91  0.71  0.69  0.71]"
      ],
      "metadata": {
        "id": "GDRxY5TuRdnD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "62.Compute the minimum-by-maximum for every row of df.\n",
        "\n",
        "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))"
      ],
      "metadata": {
        "id": "0yzL9zFfRhVC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E_wULgNdRlFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0    0.164835<br>\n",
        "1    0.103448<br>\n",
        "2    0.020202<br>\n",
        "3    0.135417<br>\n",
        "4    0.068182<br>\n",
        "5    0.139241<br>\n",
        "6    0.122449<br>\n",
        "7    0.235955<br>\n",
        "dtype: float64"
      ],
      "metadata": {
        "id": "BDksQDlIRlMF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "63.Create a new column 'penultimate' which has the second largest value of each row of df.\n",
        "\n",
        "Input\n",
        "\n",
        "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))"
      ],
      "metadata": {
        "id": "iT5eqzz5R1oT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k0c9XFO2R69U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "&nbsp;&nbsp;&nbsp;  0   1   2   3   4   5   6   7   8   9  penultimate<br>\n",
        "0  52  69  62   7  20  69  38  10  57  17           62<br>\n",
        "1  52  94  49  63   1  90  14  76  20  84           90<br>\n",
        "2  78  37  58   7  27  41  27  26  48  51           58<br>\n",
        "3   6  39  99  36  62  90  47  25  60  84           90<br>\n",
        "4  37  36  91  93  76  69  86  95  69   6           93<br>\n",
        "5   5  54  73  61  22  29  99  27  46  24           73<br>\n",
        "6  71  65  45   9  63  46   4  93  36  18           71<br>\n",
        "7  85   7  76  46  65  97  64  52  28  80           85<br>"
      ],
      "metadata": {
        "id": "3ZknvB80R7BS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "64.    Normalize all columns of df by subtracting the column mean and divide by standard deviation.\n",
        "\n",
        "    Range all columns of df such that the minimum value in each column is 0 and max is 1.\n",
        "\n",
        "Don’t use external packages like sklearn.\n",
        "\n",
        "Input\n",
        "\n",
        "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))"
      ],
      "metadata": {
        "id": "wFwHCWXESGd7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MeeS-_hrS-_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solution Q1\n",
        "\n",
        "       0     1     2     3     4     5     6     7     8     9\n",
        "0  1.09  0.64 -0.33 -0.96 -1.30  0.06  0.38  1.18 -1.60  1.66<br>\n",
        "1 -0.93 -2.36  0.87  1.47 -1.15  1.27  0.07 -0.87 -0.18  0.23<br>\n",
        "2  1.53  0.48 -0.90  0.18 -0.33  0.81 -1.29  0.34  0.06 -0.55<br>\n",
        "3  0.59 -0.24 -1.06  0.61  1.18 -1.23 -0.53 -0.45  0.34 -1.25<br>\n",
        "4  0.18  0.33  1.07  1.17  0.50 -0.26 -0.25 -1.45  1.11  1.11<br>\n",
        "5 -1.16  0.64 -0.93 -0.59 -0.15  0.63  1.02  1.13  1.20 -0.19<br>\n",
        "6 -0.58  0.07 -0.20 -0.87 -0.22 -1.62 -1.04  0.81 -1.23 -1.04<br>\n",
        "7 -0.73  0.45  1.47 -1.02  1.47  0.34  1.65 -0.71  0.31  0.02<br>\n",
        "\n",
        "Solution Q2\n",
        "\n",
        "       0     1     2     3     4     5     6     7     8     9\n",
        "0  0.16  0.00  0.71  0.98  1.00  0.42  0.43  0.00  1.00  0.00<br>\n",
        "1  0.91  1.00  0.24  0.00  0.95  0.00  0.54  0.78  0.49  0.49<br>\n",
        "2  0.00  0.05  0.93  0.52  0.65  0.16  1.00  0.32  0.41  0.76<br>\n",
        "3  0.35  0.29  1.00  0.35  0.10  0.86  0.74  0.62  0.31  1.00<br>\n",
        "4  0.50  0.10  0.16  0.12  0.35  0.53  0.65  1.00  0.03  0.19<br>\n",
        "5  1.00  0.00  0.95  0.83  0.58  0.22  0.22  0.02  0.00  0.64<br>\n",
        "6  0.78  0.19  0.66  0.94  0.61  1.00  0.91  0.14  0.87  0.93<br>\n",
        "7  0.84  0.06  0.00  1.00  0.00  0.32  0.00  0.72  0.32  0.56<br>"
      ],
      "metadata": {
        "id": "8hHZZ_MZS_EP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AwC_fyuGTPtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "65.Compute the correlation of each row of df with its succeeding row.\n",
        "\n",
        "Input\n",
        "\n",
        "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))"
      ],
      "metadata": {
        "id": "5y7Is0stTQKr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZXQZmSoDTWsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;   1&nbsp;&nbsp;   2&nbsp;&nbsp;&nbsp;   3&nbsp;&nbsp;   4&nbsp;&nbsp;   5&nbsp;&nbsp;   6&nbsp;&nbsp;   7&nbsp;&nbsp;   8&nbsp;&nbsp;   9<br>\n",
        "0  93  49  26   2  96  56  11  73  90  65<br>\n",
        "1  54  17  47  52  65   9  21  87  94   4<br>\n",
        "2  51  11  44  77  37  57  17  25  95  26<br>\n",
        "3  84   8  61  43  63  63  59  65  69  29<br>\n",
        "4   8  27  53  95  10  35  16  61  39  83<br>\n",
        "5  30  70  91  26  12  44  37  71  21  48<br>\n",
        "6  66  44  47  44  29  99  86  78  31   1<br>\n",
        "7  17  40  28  12  89  95  79  54  81  47<br>\n",
        "\n",
        "[0.40999999999999998,\n",
        " 0.47999999999999998,\n",
        " 0.42999999999999999,\n",
        " -0.37,\n",
        " 0.23000000000000001,\n",
        " 0.14000000000000001,\n",
        " 0.22]"
      ],
      "metadata": {
        "id": "_80tLe45TWxf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "66.Replace both values in both diagonals of df with 0.\n",
        "\n",
        "Input\n",
        "\n",
        "df = pd.DataFrame(np.random.randint(1,100, 100).reshape(10, -1))\n",
        "\n",
        "df\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;0   1   2   3   4   5   6   7   8   9<br>\n",
        " 0  11  46  26  44  11  62  18  70  68  26<br>\n",
        " 1  87  71  52  50  81  43  83  39   3  59<br>\n",
        " 2  47  76  93  77  73   2   2  16  14  26<br>\n",
        " 3  64  18  74  22  16  37  60   8  66  39<br>\n",
        " 4  10  18  39  98  25   8  32   6   3  29<br>\n",
        " 5  29  91  27  86  23  84  28  31  97  10<br>\n",
        " 6  37  71  70  65   4  72  82  89  12  97<br>\n",
        " 7  65  22  97  75  17  10  43  78  12  77<br>\n",
        " 8  47  57  96  55  17  83  61  85  26  86<br>\n",
        " 9  76  80  28  45  77  12  67  80   7  63"
      ],
      "metadata": {
        "id": "zzhYE7yIToUD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ygIgaugiA0vK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "&nbsp;&nbsp;&nbsp;     0   1   2   3   4   5   6   7   8   9<br>\n",
        " 0   0  46  26  44  11  62  18  70  68   0<br>\n",
        " 1  87   0  52  50  81  43  83  39   0  59<br>\n",
        " 2  47  76   0  77  73   2   2   0  14  26<br>\n",
        " 3  64  18  74   0  16  37   0   8  66  39<br>\n",
        " 4  10  18  39  98   0   0  32   6   3  29<br>\n",
        " 5  29  91  27  86   0   0  28  31  97  10<br>\n",
        " 6  37  71  70   0   4  72   0  89  12  97<br>\n",
        " 7  65  22   0  75  17  10  43   0  12  77<br>\n",
        " 8  47   0  96  55  17  83  61  85   0  86<br>\n",
        " 9   0  80  28  45  77  12  67  80   7   0\n",
        "\n"
      ],
      "metadata": {
        "id": "24PWQKBNA0-s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "67.This is a question related to understanding of grouped dataframe. From df_grouped, get the group belonging to 'apple' as a dataframe.\n",
        "\n",
        "Input\n",
        "\n",
        "df = pd.DataFrame({'col1': ['apple', 'banana', 'orange'] * 3,\n",
        "                   'col2': np.random.rand(9),\n",
        "                   'col3': np.random.randint(0, 15, 9)})\n",
        "\n",
        "df_grouped = df.groupby(['col1'])"
      ],
      "metadata": {
        "id": "eV9MiVW2BCKh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vD8td424BIwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    col1      col2  col3\n",
        "0  apple  0.673434   &nbsp;&nbsp;&nbsp;  7<br>\n",
        "3  apple  0.182348   &nbsp;&nbsp; 14<br>\n",
        "6  apple  0.050457    &nbsp;&nbsp;&nbsp; 3"
      ],
      "metadata": {
        "id": "z2TeT5TJBI2j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "68.In df, find the second largest value of 'taste' for 'banana'\n",
        "\n",
        " Input\n",
        "\n",
        "df = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n",
        "                   'rating': np.random.rand(9),\n",
        "                   'price': np.random.randint(0, 15, 9)})"
      ],
      "metadata": {
        "id": "Ty-DM63gBXRq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wsTtLvHuBc5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    fruit  price     taste\n",
        "0   apple      7 &nbsp; 0.190229<br>\n",
        "1  banana      2 &nbsp; 0.438063<br>\n",
        "2  orange      1 &nbsp; 0.860182<br>\n",
        "3   apple      6 &nbsp; 0.042149<br>\n",
        "4  banana      2 &nbsp; 0.896021<br>\n",
        "5  orange      5 &nbsp; 0.255107<br>\n",
        "6   apple      6 &nbsp; 0.874533<br>\n",
        "7  banana      4 &nbsp; 0.696274<br>\n",
        "8  orange      9 &nbsp; 0.140713\n",
        "\n",
        "0.69627423645996078"
      ],
      "metadata": {
        "id": "Pvy2bBYHBc_h"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xg8N2qerBt8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "69.In df, Compute the mean price of every fruit, while keeping the fruit as another column instead of an index.\n",
        "\n",
        "Input\n",
        "\n",
        "df = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n",
        "                   'rating': np.random.rand(9),\n",
        "                   'price': np.random.randint(0, 15, 9)})"
      ],
      "metadata": {
        "id": "wo6d2RUXBuBP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CbHD0kDXB0tX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    fruit      price\n",
        "0   apple  11.000000<br>\n",
        "1  banana   6.333333<br>\n",
        "2  orange   6.333333"
      ],
      "metadata": {
        "id": "gjdIUC9lB02D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "70.Join dataframes df1 and df2 by ‘fruit-pazham’ and ‘weight-kilo’.\n",
        "\n",
        "Input\n",
        "\n",
        "df1 = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n",
        "                    'weight': ['high', 'medium', 'low'] * 3,\n",
        "                    'price': np.random.randint(0, 15, 9)})\n",
        "\n",
        "df2 = pd.DataFrame({'pazham': ['apple', 'orange', 'pine'] * 2,\n",
        "                    'kilo': ['high', 'low'] * 3,\n",
        "                    'price': np.random.randint(0, 15, 6)})"
      ],
      "metadata": {
        "id": "w3yJaVyuB4ZW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ALszd9NZCAxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " \tfruit\tprice_left\tweight\tpazham\tpounds\tprice_right\n",
        "0\tapple\t5\thigh\tapple\thigh\t11<br>\n",
        "1\tapple\t10\thigh\tapple\thigh\t11<br>\n",
        "2\tapple\t8\thigh\tapple\thigh\t11<br>\n",
        "3\torange\t6\tlow\torange\tlow\t6<br>\n",
        "4\torange\t7\tlow\torange\tlow\t6<br>\n",
        "5\torange\t0\tlow\torange\tlow\t6"
      ],
      "metadata": {
        "id": "lJM7m4wnCA2z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "71.From df1, remove the rows that are present in df2. All three columns must be the same.\n",
        "\n",
        "Input\n",
        "\n",
        "df1 = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n",
        "                    'weight': ['high', 'medium', 'low'] * 3,\n",
        "                    'price': np.random.randint(0, 15, 9)})\n",
        "\n",
        "df2 = pd.DataFrame({'pazham': ['apple', 'orange', 'pine'] * 2,\n",
        "                    'kilo': ['high', 'low'] * 3,\n",
        "                    'price': np.random.randint(0, 15, 6)})"
      ],
      "metadata": {
        "id": "eu_qNVw_CFoN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YyUuhQyECKz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    fruit  price  weight\n",
        "2  banana      2     low<br>\n",
        "3   apple      3    high<br>\n",
        "4  orange      4  medium<br>\n",
        "5  banana      5     low<br>\n",
        "6   apple      6    high<br>\n",
        "7  orange      7  medium<br>\n",
        "8  banana      8     low<br>"
      ],
      "metadata": {
        "id": "qwDCI_TECK5J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "72.get the positions where values of two columns match\n",
        "\n",
        "Input\n",
        "\n",
        "df = pd.DataFrame({'fruit1': np.random.choice(['apple', 'orange', 'banana'], 10),\n",
        "                    'fruit2': np.random.choice(['apple', 'orange', 'banana'], 10)})\n"
      ],
      "metadata": {
        "id": "9zzL3BlpCULd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0s8Wk7s1Ce1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(array([1, 5, 9]),)"
      ],
      "metadata": {
        "id": "4DA3y5KQCe6_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "73.reate two new columns in df, one of which is a lag1 (shift column a down by 1 row) of column ‘a’ and the other is a lead1 (shift column b up by 1 row). Input\n",
        "\n",
        "df = pd.DataFrame(np.random.randint(1, 100, 20).reshape(-1, 4), columns = list('abcd'))\n",
        "\n",
        "    a   b   c   d\n",
        "0  66  34  76  47<br>\n",
        "1  20  86  10  81<br>\n",
        "2  75  73  51  28<br>\n",
        "3   1   1   9  83<br>\n",
        "4  30  47  67   4"
      ],
      "metadata": {
        "id": "R2e5QFhwClNw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jJdKukuKCxi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    a   b   c   d  a_lag1  b_lead1\n",
        "0  66  34  76  47     NaN     86.0<br>\n",
        "1  20  86  10  81    66.0     73.0<br>\n",
        "2  75  73  51  28    20.0      1.0<br>\n",
        "3   1   1   9  83    75.0     47.0<br>\n",
        "4  30  47  67   4     1.0      NaN<br>"
      ],
      "metadata": {
        "id": "6ES8QsNdCxpQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "74.Get the frequency of unique values in the entire dataframe df.\n",
        "\n",
        " Input\n",
        "\n",
        "df = pd.DataFrame(np.random.randint(1, 10, 20).reshape(-1, 4), columns = list('abcd'))"
      ],
      "metadata": {
        "id": "Brh3GulmC11w"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9v6HdYj1C9fG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5    4<br>\n",
        "4    4<br>\n",
        "9    3<br>\n",
        "8    2<br>\n",
        "7    2<br>\n",
        "3    2<br>\n",
        "6    1<br>\n",
        "2    1<br>\n",
        "1    1<br>\n",
        "dtype: int64"
      ],
      "metadata": {
        "id": "OOmtKeiWC9j_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "75.Split the string column in df to form a dataframe with 3 columns as shown. Input\n",
        "\n",
        "df = pd.DataFrame([\"STD, City    State\",<br>\n",
        "\"33, Kolkata    West Bengal\",<br>\n",
        "\"44, Chennai    Tamil Nadu\",<br>\n",
        "\"40, Hyderabad    Telengana\",<br>\n",
        "\"80, Bangalore    Karnataka\"], columns=['row'])\n",
        "\n",
        "print(df)\n",
        "\n",
        ">                         row\n",
        "> 0          STD, City\\tState<br>\n",
        "> 1  33, Kolkata\\tWest Bengal<br>\n",
        "> 2   44, Chennai\\tTamil Nadu<br>\n",
        "> 3  40, Hyderabad\\tTelengana<br>\n",
        "> 4  80, Bangalore\\tKarnataka"
      ],
      "metadata": {
        "id": "90xsB6fTDE6M"
      }
    }
  ]
}